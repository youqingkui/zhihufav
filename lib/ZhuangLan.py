#!/usr/bin/env python#coding=utf-8import requestsimport osimport randomimport binasciiimport redisfrom Evernote import EvernoteMethodfrom bs4 import BeautifulSoupfrom note_store import noteStorefrom logger_fun import loggerfrom instapush_notify import InstaPushNotifys = requests.session()redis_obj = redis.Redis(host='localhost', port=6379, db=0)class CollectionArticle():    def __init__(self, url, parent_note, receipt_handle):        self.url = url        self.parent_note = parent_note        self.dev_token = os.environ.get('DeveloperToken')        # self.noteStore = EvernoteMethod.getNoteStore(self.dev_token)        self.noteStore = noteStore        self.receipt_handle = receipt_handle        self.headers = {'User-Agent':'osee2unifiedRelease/332 CFNetwork/711.3.18 Darwin/14.0.0',           'Authorization':os.environ.get('Authorization'),           'Content-Type':'application/json'}    def get_content(self):        logger.info("get_content url %s" % self.url)        r = requests.get(self.url, headers=self.headers)        logger.info("get_content res %s " % r.text)        res_json = r.json()        content = res_json.get('content', '')        soup = BeautifulSoup(content, "html5lib")        soup.find_all(self.remove_attrs)        soup.html.unwrap()        soup.head.unwrap()        soup.body.unwrap()        title = res_json.get('title', '')        # question_id = res_json.get('question', {}).get('id', '')        id    = res_json.get('id', '')        note_url = 'https://zhuanlan.zhihu.com/p/%s' % (id)        res = self.change_img(soup)        title_list = title.split('\n')        title = ''        for t in title_list:            title += t        # remove \b        title = title.replace('\b', '')        logger.info("note_url %s" % note_url)        logger.info("title %s" % title)        html_content = str(soup)        res = EvernoteMethod.makeNote(self.noteStore, title.encode('utf8'),                                html_content, note_url, res, self.parent_note)    def remove_attrs(self, tag):        attrs = tag.attrs        for k, v in attrs.items():            if k not in ['src', 'href']:                del tag.attrs[k]    def change_img(self, soup):        img_tags = soup.find_all("img")        img_arr = [img.attrs['src'] for img in img_tags if img['src']]        resources = EvernoteMethod.getRemoteRes(img_arr)        index = 0        for img in img_tags:            if img['src']:                hexhash = binascii.hexlify(resources[index].data.bodyHash)                new_tag = soup.new_tag('en-media')                new_tag['type'] = resources[index].mime                new_tag['hash'] = hexhash                img.replace_with(new_tag)                index += 1        return resourcesclass CollectionZhuanLan(object):    def __init__(self, url):        self.url = url        self.headers = {            'User-Agent': 'osee2unifiedRelease/332 CFNetwork/711.3.18 Darwin/14.0.0',            'Authorization': os.environ.get('Authorization'),            'Content-Type': 'application/json',            'x-api-version': "3.0.42",            'accept-language': "zh-Hans-CN;q=1, en-US;q=0.9",            'accept': "*/*",            'accept-encoding': "gzip, deflate"        }        self.force_check = True if random.randint(0, 9) > 7 else False    def get_list(self, url):        r = s.get(url, headers=self.headers)        res_json = r.json()        data_info = res_json.get('data', [])        next_url = None        if data_info and self.force_check:            paging_dict = res_json.get('paging', {})            next_url = paging_dict.get('next', None)        for data in data_info:            type_info = data.get('type', '')            if type_info == 'article':                data_url = data.get('url')                data_id = (data.get('id'))                data_title = data.get('title')                if not data_url or not data_id or not data_title:                    logger.error("%s error" % data)                    continue                if redis_obj.sismember('zhihu_zhuanlan_id', data_id):                    logger.warning("%s %s %s exits" % (data_url, data_id, data_title))                    continue                logger.info("+++++++++++++++++++++++++++++++++++++++++++")                logger.info(data_url)                logger.info(data_id)                logger.info(data_title)                self.push_fav(data)                logger.info("+++++++++++++++++++++++++++++++++++++++++++")                logger.info("\n")                # return        if next_url:            logger.info("next url %s" % next_url)            self.get_list(next_url)    def push_fav(self, dict_info):        url = dict_info.get('url', '')        data_id = dict_info.get('id')        title = dict_info.get('title')        # f = CollectionArticle(url, '735b3e76-e7f5-462c-84d0-bb1109bcd7dd', '')        f = CollectionArticle(url, 'f082258a-fd9a-4713-98a0-d85fa838f019', '')        f.get_content()        redis_obj.sadd('zhihu_zhuanlan_id', data_id)        InstaPushNotify.notify(title, type_info=2)if __name__ == '__main__':    try:        czlf = CollectionZhuanLan('https://api.zhihu.com/collections/29469118/contents?excerpt_len=75')        czlf.get_list(czlf.url)    except Exception, e:        logger.error(Exception)        logger.error(e)        InstaPushNotify.notify("error e:%s" % e , type_info=2)